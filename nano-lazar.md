---
author: |
  Christoph Helma^1^, Micha Rautenberg^1^, Denis Gebele^1^
title: |
  nano-lazar: Validation of read across predictions for nanoparticle toxicities
include-before: ^1^ in silico toxicology gmbh,  Basel, Switzerland
keywords: (Q)SAR, read-across, nanoparticle
date: \today
abstract: " "
#documentclass: achemso
bibliography: references.bibtex
bibliographystyle: achemso
figPrefix: Figure
eqnPrefix: Equation
tblPrefix: Table
output:
  pdf_document:
    fig_caption: yes
header-includes:
#  - \usepackage{lineno}
#  - \linenumbers
...

Introduction
============

Data requirements
-----------------

Calculation of similarities
  intersection of physchem descriptors

Experimental data for similar compounds

Use cases
---------

- no nanoparticle information: core+coating properties
- physchem measurements
- proteomics


Objectives
----------

- Evaluate currently available nanoparticle data for read across predictions
- Compare read across predictions based on
  - calculated core and coating properties
  - measured nanoparticle properties
  - nanoparticle protein corona


Reproducible research
---------------------

With this investigation we intend to provide an example of reproducible
research.

This manuscript has been generated by a build system that
pulls results and figures directly from validation data.
Source code for the manuscript and the associated libraries
are publicly available under a GPL license from the GitHub
repositories https://github.com/opentox/nano-lazar-paper
(manuscript) and https://github.com/opentox/lazar (lazar framework).

For the reproduction of results with exactly the same libraries, dependencies and programs at the time of the manuscript creation we provide additionally 
a self-contained docker image at DockerHub https://hub.docker.com/r/insilicotox/nano-lazar-paper/.

Please note that recreating validations will not lead to exactly the same results, because we deliberately avoid setting a predefined random seed for crossvalidation folds, in order to avoid overfitting for fixed training/test set splits.

TODO: GUI @ https://nano-lazar.in-silico.ch

Methods
=======

Datasets
--------

Nanoparticle characterisations and toxicities were mirrored from the eNanoMapper database [@Jeliazkova15] via its REST API.

Algorithms
----------

For this study we have adapted the modular lazar (*la*zy *s*tructure *a*ctivity *r*elationships)
read across framework [@Maunz2013] for nanoparticle model development and validation.

lazar was originally developed for small molecules with a defined chemical structure and uses chemical fingerprints for the identification of similar compounds (*neighbors*). Nanoparticles in contrast do not have clearly defined chemical structures, but they can be characterised in terms of measured size, shape, physicochemical properties or the interaction with biological macromolecules. Within nano-lazar we use these properties for the identification of similar nanoparticles (*neighbors*) and as descriptors for local QSAR models.

nano-lazar follows the following basic workflow: For a given nanoparticle
lazar 

- searches in a database for similar nanoparticles (*neighbors*) with experimental
  data, 
- builds a local QSAR model with these neighbors and 
- uses this model to predict the unknown activity of the query compound.

This procedure resembles an automated version of *read across* predictions in
toxicology, in machine learning terms it would be classified as a
*k-nearest-neighbor* algorithm.

Apart from this basic workflow nano-lazar is completely modular and allows the
researcher to use arbitrary algorithms for similarity searches and local QSAR
modelling. Within this study we are using and comparing the following algorithms:

### Feature selection

  Nanoparticle properties in the eNanoMapper database have not been measured with read across and QSAR modelling in mind. For this reason the database contains a lot of features that are irrelevant for toxicity. Using all available features for similarity calculations leads neighbor sets that are unsuitable for local QSAR models, because large numbers of irrelevant features override the impact of relevant features.

  TODO: example, results section?

  For this reason we return to the lazar concept of *activity specific similarities* [@Maunz2013], by selecting features that correlate with a particular toxicity endpoint (Pearson correlation p-value < 0.05), which leads to a set of *relevant features*.
  This procedure is repeated separately for each crossvalidation fold, to avoid overfitted models [@????].

### Neighbor identification

Similarity calculations are based on the reduced set of relevant features that correlate well with the toxic effect. 

The chemical similarity between two nanoparticles 
is defined as the *weighted cosine similarity* of their scaled and centered relevant feature vectors, where the contribution of each feature is weighted by its Pearson correlation coefficient.

A similarity threshold of $sim > 0.5$ is used for the identification of neighbors for
local QSAR models. Nanoparticles that are identical to the query particle
are eliminated from the neighbors to obtain unbiased predictions in the presence of duplicates.

### Local QSAR models and predictions

Only similar nanoparticles (*neighbors*) above the threshold are used for local
QSAR models.  In this investigation we are comparing three local regression algorithms:

- weighted local average (WA)
- weighted partial least squares regression (PLS)
- weighted random forests (RF)

In all cases neighbor contributions are weighted by their similarity.
The weighted local average algorithm serves as a simple and fast benchmark algorithm, whereas 
partial least squares and random forests are known to work well for a variety of QSAR problems. 
Partial least squares and random forest models use the `caret` R package
[@Kuhn08].  Models are trained with the default
`caret` settings, optimizing the number of PLS components or number of variables available for splitting at each RF tree node
 by bootstrap resampling.

Finally the local model is applied to predict the activity of the query
nanoparticle. The RMSE of bootstrapped model predictions is used to construct 95\%
prediction intervals at 1.96*RMSE.

If PLS/RF modelling or prediction fails, the program resorts to using the weighted
average method.

### Applicability domain

The applicability domain of lazar models is determined by the diversity of the
training data. If no similar compounds are found in the training data (either
because there are no similar nanoparticles or because similarities cannot be
determined du to the lack of mesured properties) no predictions will be
generated. Warnings are also issued, if local QSAR model building or model
predictions fail. 

The variability of local model predictions is reflected in the prediction
interval.

### Validation

  For validation purposes we use the 
results from 3 repeated 10-fold crossvalidations with independent training/test
set splits. Feature selection is performed separately for each training dataset to avoid overfitting. For the same reason we do not use a fixed random seed for training/test set splits. This leads to slightly different results for each repeated crossvalidation run, but it allows to estimate the variability of validation results due to random training/test splits.

Results
=======

Data requirements
-----------------

The first in our experiments step was to determine the toxicity endpoints currently available in the eNanoMapper database that have sufficient data for the creation and validation of read across models. [@tbl:endpoints] summarizes the endpoints and data points that are currently available in eNanoMapper.


Endpoint | Nr. nanoparticles
---------|------------------
TODO | TODO

: Summary of toxicity endpoints currently available in eNanoMapper {#tbl:endpoints}

In order to 
a threshold of at least 100 examples 
This criterea is currently fulfilled only by the *Net cell association* endpoint of the *Protein corona* dataset, which contains TODO Gold and Silver particles that are characterized by physchem properties and their interaction with proteins in human serum. For this dataset we have found TODO (NTUA abstract?) reference studies [@Walkey14, @Liu15].

TODO: literature search

https://scholar.google.com/scholar?q=protein+corona+nanoparticles+qsar&btnG=&hl=en&as_sdt=0%2C5&as_vis=1

TODO: description of parameters

Repeated crossvalidations
-------------------------

This section presents the results of repeated crossvalidation experiments with nanoparticle read across models for the *Net cell association* endpoint (log2 transformed).

We have investigated the following descriptor classes 

- Physchem properties TODO size, shape??
- Proteomics data (TODO erklaeren)
- Physchem properties and proteomics data

and the local regression algorithms

- local weighted average
- local weighted partial least squares regression
- local weighted random forests

### Physchem properties

Algorithm        | $r^2$                                      | RMSE                        
-----------------|--------------------------------------------|---------------------------------------
Weighted average | `! scripts/values.rb weighted_average P-CHEM r_squared` | `! scripts/values.rb weighted_average P-CHEM rmse` 
Partial least squares | `! scripts/values.rb pls P-CHEM r_squared` | `! scripts/values.rb pls P-CHEM rmse` 
Random forest | `! scripts/values.rb random_forests P-CHEM r_squared` | `! scripts/values.rb random_forests P-CHEM rmse` 

: Repeated crossvalidation results for models with physchem properties, $**$ best results of all experiments, $*$ no statistically significant difference to best results ($p > 0.05$) {#tbl:pchem}

![Correlation of log2 transformed net cell association measurements with weighted average predictions using physchem properties.](figures/weighted_average-pchem-crossvalidations.pdf){#fig:wa-pchem}

![Correlation of log2 transformed net cell association measurements with partial least squares predictions using physchem properties.](figures/pls-pchem-crossvalidations.pdf){#fig:pls-pchem}

![Correlation of log2 transformed net cell association measurements with random forest predictions using physchem properties.](figures/random_forests-pchem-crossvalidations.pdf){#fig:rf-pchem}


### Protein corona

Algorithm        | $r^2$                                      | RMSE                        
-----------------|--------------------------------------------|---------------------------------------
Weighted average | `! scripts/values.rb weighted_average Proteomics r_squared` | `! scripts/values.rb weighted_average Proteomics rmse` 
Partial least squares | `! scripts/values.rb pls Proteomics r_squared` | `! scripts/values.rb pls Proteomics rmse` 
Random forest | `! scripts/values.rb random_forests Proteomics r_squared` | `! scripts/values.rb random_forests Proteomics rmse` 

: Repeated crossvalidation results for models with protein corona data, $**$ best results of all experiments, $*$ no statistically significant difference to best results ($p > 0.05$)

![Correlation of log2 transformed net cell association measurements with weighted average predictions using protein corona data.](figures/weighted_average-proteomics-crossvalidations.pdf){#fig:wa-prot}

![Correlation of log2 transformed net cell association measurements with partial least squares predictions using protein corona data.](figures/pls-proteomics-crossvalidations.pdf){#fig:pls-prot}

![Correlation of log2 transformed net cell association measurements with random forest predictions using protein corona data.](figures/random_forests-proteomics-crossvalidations.pdf){#fig:rf-prot}


### Physchem properties and protein corona

Algorithm        | $r^2$                                      | RMSE                        
-----------------|--------------------------------------------|---------------------------------------
Weighted average | `! scripts/values.rb weighted_average all r_squared` | `! scripts/values.rb weighted_average all rmse` 
Partial least squares | `! scripts/values.rb pls all r_squared` | `! scripts/values.rb pls all rmse` 
Random forest | **`! scripts/values.rb random_forests all r_squared`** | `! scripts/values.rb random_forests all rmse` 

: Repeated crossvalidation results for models with physchem properties and protein corona data, $**$ best results of all experiments, $*$ no statistically significant difference to best results ($p > 0.05$)

![Correlation of log2 transformed net cell association measurements with weighted average predictions using physchem properties and protein corona data.](figures/weighted_average-all-crossvalidations.pdf){#fig:wa-all}

![Correlation of log2 transformed net cell association measurements with partial least squares predictions using physchem properties and protein corona data.](figures/pls-all-crossvalidations.pdf){#fig:pls-all}

![Correlation of log2 transformed net cell association measurements with random forest predictions using physchem properties and protein corona data.](figures/random_forests-all-crossvalidations.pdf){#fig:rf-all}

Discussion
==========

Liu paper:

descriptor selection not included in cv!!
prediction accuracy != r^2
uses bootstrap and strange r^2 which includes training set performance

all papers: no silver particles

Conclusion
==========

Acknowledgements
================

This work was performed as part of the EU FP7 project "Nanomaterials safety assessment: Ontology,
database(s) for modelling and risk assessment
Development of an integrated multi-scale modelling
environment for nanomaterials and systems by design" (Theme NMP.2013.1.3-2 NMP.2013.1.4-1, Grant agreement no: 604134).

References
==========
